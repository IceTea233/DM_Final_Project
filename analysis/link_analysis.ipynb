{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10642 entries, 0 to 10641\n",
      "Data columns (total 31 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   title                  10642 non-null  object \n",
      " 1   company                10642 non-null  object \n",
      " 2   rating                 10642 non-null  float64\n",
      " 3   review_count           10642 non-null  int64  \n",
      " 4   urgently_hiring        10642 non-null  bool   \n",
      " 5   snippet                10642 non-null  object \n",
      " 6   dradis_job             10642 non-null  bool   \n",
      " 7   new_job                10642 non-null  bool   \n",
      " 8   sponsored              10642 non-null  bool   \n",
      " 9   featured_employer      10642 non-null  bool   \n",
      " 10  indeed_applyable       10642 non-null  bool   \n",
      " 11  source_id              10642 non-null  int64  \n",
      " 12  job_location_postal    10642 non-null  float64\n",
      " 13  salary_min             10642 non-null  int64  \n",
      " 14  salary_max             10642 non-null  int64  \n",
      " 15  company_has_link       10642 non-null  bool   \n",
      " 16  job_type_Full-time     10642 non-null  bool   \n",
      " 17  job_type_Part-time     10642 non-null  bool   \n",
      " 18  job_type_Temporary     10642 non-null  bool   \n",
      " 19  job_type_Contract      10642 non-null  bool   \n",
      " 20  job_type_Internship    10642 non-null  bool   \n",
      " 21  job_type_N/A           10642 non-null  bool   \n",
      " 22  relative_time          10642 non-null  int64  \n",
      " 23  activity_date          10642 non-null  int64  \n",
      " 24  activity_date_na       10642 non-null  bool   \n",
      " 25  location_remote        10642 non-null  bool   \n",
      " 26  no_postal              10642 non-null  bool   \n",
      " 27  remote_work_model      10642 non-null  int64  \n",
      " 28  hires_needed_na        10642 non-null  bool   \n",
      " 29  hires_needed_exact_na  10642 non-null  bool   \n",
      " 30  hires_needed_exact     10642 non-null  int64  \n",
      "dtypes: bool(18), float64(2), int64(8), object(3)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/train_preprocess.csv', encoding='latin-1')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10642 entries, 0 to 10641\n",
      "Data columns (total 34 columns):\n",
      " #   Column                 Non-Null Count  Dtype   \n",
      "---  ------                 --------------  -----   \n",
      " 0   title                  10642 non-null  object  \n",
      " 1   company                10642 non-null  object  \n",
      " 2   rating                 10642 non-null  float64 \n",
      " 3   review_count           10642 non-null  int64   \n",
      " 4   urgently_hiring        10642 non-null  bool    \n",
      " 5   snippet                10642 non-null  object  \n",
      " 6   dradis_job             10642 non-null  bool    \n",
      " 7   new_job                10642 non-null  bool    \n",
      " 8   sponsored              10642 non-null  bool    \n",
      " 9   featured_employer      10642 non-null  bool    \n",
      " 10  indeed_applyable       10642 non-null  bool    \n",
      " 11  source_id              10642 non-null  int64   \n",
      " 12  job_location_postal    10642 non-null  float64 \n",
      " 13  salary_min             10642 non-null  int64   \n",
      " 14  salary_max             10642 non-null  int64   \n",
      " 15  company_has_link       10642 non-null  bool    \n",
      " 16  job_type_Full-time     10642 non-null  bool    \n",
      " 17  job_type_Part-time     10642 non-null  bool    \n",
      " 18  job_type_Temporary     10642 non-null  bool    \n",
      " 19  job_type_Contract      10642 non-null  bool    \n",
      " 20  job_type_Internship    10642 non-null  bool    \n",
      " 21  job_type_N/A           10642 non-null  bool    \n",
      " 22  relative_time          10642 non-null  int64   \n",
      " 23  activity_date          10642 non-null  int64   \n",
      " 24  activity_date_na       10642 non-null  bool    \n",
      " 25  location_remote        10642 non-null  bool    \n",
      " 26  no_postal              10642 non-null  bool    \n",
      " 27  remote_work_model      10642 non-null  int64   \n",
      " 28  hires_needed_na        10642 non-null  bool    \n",
      " 29  hires_needed_exact_na  10642 non-null  bool    \n",
      " 30  hires_needed_exact     10642 non-null  int64   \n",
      " 31  average_salary         10642 non-null  float64 \n",
      " 32  salary_ratio           10642 non-null  float64 \n",
      " 33  salary_range           10642 non-null  category\n",
      "dtypes: bool(18), category(1), float64(4), int64(8), object(3)\n",
      "memory usage: 1.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Extract information from salary\n",
    "df['average_salary'] = (df['salary_min'] + df['salary_max']) / 2\n",
    "\n",
    "# Calculate the ratio M/m\n",
    "df['salary_ratio'] = df['salary_max'] / df['salary_min']\n",
    "\n",
    "# Classify into Low, Medium, or High based on the specified criteria\n",
    "df['salary_range'] = pd.cut(df['salary_ratio'],\n",
    "                            bins=[-float('inf'), 1.25, 1.5, float('inf')],\n",
    "                            labels=['Low', 'Medium', 'High'],\n",
    "                            right=False) # Ensure that the intervals are left-closed\n",
    "\n",
    "\n",
    "# Print the count of each salary range\n",
    "# print(df['salary_range'].value_counts())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the block below to do experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "min_support = 0.6\n",
    "min_confidence = 0.6\n",
    "\n",
    "# targets\n",
    "feature_df = df.select_dtypes(include=['bool', 'category'])\n",
    "grouped_df = feature_df.groupby('salary_range')\n",
    "labels = ['Low', 'Medium', 'High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apriori_python import apriori\n",
    "\n",
    "\n",
    "results = dict()\n",
    "for label in labels:\n",
    "    group = grouped_df.get_group(label).drop('salary_range', axis=1)\n",
    "\n",
    "    # Prepare feature sets for Apriori\n",
    "    group_dict = group.to_dict('records')\n",
    "    feature_set_list = []\n",
    "    for features in group_dict:\n",
    "        feature_set = [name for name, value in features.items() if value]\n",
    "        feature_set_list.append(feature_set)\n",
    "    \n",
    "    results[label] = apriori(feature_set_list, minSup=min_support, minConf=min_confidence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './association/rule/Low.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m rules\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m2\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(rule_directory, label \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m output_file:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m premise, claim, confidence \u001b[38;5;129;01min\u001b[39;00m rules:\n\u001b[1;32m     25\u001b[0m         output_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfidence\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpremise\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m => \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclaim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DM_Final_Project-H3JCywuf/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './association/rule/Low.txt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pp\n",
    "\n",
    "for label in labels:\n",
    "    freq_feature_set, rules = results[label]\n",
    "    \n",
    "    freq_set_directory = './association/frequent_set'\n",
    "    rule_directory = './association/rule'\n",
    "    if not os.path.exists(freq_set_directory):\n",
    "        os.makedirs(freq_set_directory)\n",
    "\n",
    "    # output result for frequent sets\n",
    "    file_path = os.path.join(freq_set_directory, label + '.txt')\n",
    "    with open(file_path, 'w+') as output_file:\n",
    "        for size, feature_sets in freq_feature_set.items():\n",
    "            output_file.write(f'Size = {size}\\n')\n",
    "            for feature_set in feature_sets:\n",
    "                output_file.write(f'....{tuple(feature_set)}\\n')\n",
    "    \n",
    "    # output result for rules\n",
    "    rules.sort(key=lambda x: x[2], reverse=True)\n",
    "    file_path = os.path.join(rule_directory, label + '.txt')\n",
    "    with open(file_path, 'w+') as output_file:\n",
    "        for premise, claim, confidence in rules:\n",
    "            output_file.write(f'{confidence:.3f}: {premise} => {claim}\\n')\n",
    "# pp(sorted(rules, key=lambda x: x[2], reverse=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM_Final_Project-H3JCywuf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
